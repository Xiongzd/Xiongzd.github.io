<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>graduation_crawler</title>
      <link href="2021/02/21/graduation-crawler/"/>
      <url>2021/02/21/graduation-crawler/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>使用PyTorch搭建LSTM进行风速时间序列预测——本科毕设:Part2</title>
      <link href="2021/02/21/graduation-lstm/"/>
      <url>2021/02/21/graduation-lstm/</url>
      
        <content type="html"><![CDATA[<h1 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1. 数据预处理"></a>1. 数据预处理</h1><p>根据前文，将风速时间序列使用CEEMDAN分解，如图1所示，得到数个固有模态函数的子序列集和，本文将针对其中数个固有模态函数作为训练、验证集。</p><img src="/2021/02/21/graduation-lstm/ceemdan.png" width="400" height="300" alt="图1. 经过CEEMDAN分解的风速时间序列"><p>其中部分数据如图2所示，其中1-12为分解后的固有模态函数序列，0为原始风速序列。<br><img src="/2021/02/21/graduation-lstm/data.png" width="400" height="300" alt="图2. 经过CEEMDAN分解的风速时间序列部分数据"></p><h1 id="2-LSTM结构设计"><a href="#2-LSTM结构设计" class="headerlink" title="2. LSTM结构设计"></a>2. LSTM结构设计</h1><p>在完成LSTM模型的代码之前，为了方便以后的操作，我决定先完成一个配置文件<code>config.json</code>来完成LSTM模型的参数初始化。在此文件中定义了各种模型训练的参数和模型的结构参数。</p><pre class="line-numbers language-js" data-language="js"><code class="language-js"><span class="token comment">// file name: config.json</span><span class="token punctuation">{</span>    <span class="token string">"data"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token string">"filename"</span><span class="token operator">:</span> <span class="token string">"features.xls"</span><span class="token punctuation">,</span>        <span class="token string">"columns"</span><span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token comment">// 选择子序列集中的1、2、5、6、11以及原始序列0的数据作为训练集</span>            <span class="token number">0</span><span class="token punctuation">,</span>            <span class="token number">1</span><span class="token punctuation">,</span>            <span class="token number">2</span><span class="token punctuation">,</span>            <span class="token number">5</span><span class="token punctuation">,</span>            <span class="token number">6</span><span class="token punctuation">,</span>            <span class="token number">11</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"sequence_length"</span><span class="token operator">:</span> <span class="token number">20</span><span class="token punctuation">,</span>  <span class="token comment">// 使用前20个点来预测一个新的点</span>        <span class="token string">"train_test_split"</span><span class="token operator">:</span> <span class="token number">0.75</span>    <span class="token comment">// 使用前75%作为训练集、余下的25%作为验证集使用</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token string">"training"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token string">"epochs"</span><span class="token operator">:</span> <span class="token number">5000</span><span class="token punctuation">,</span>     <span class="token comment">// 最大迭代次数</span>        <span class="token string">"batch_size"</span><span class="token operator">:</span> <span class="token number">120</span>   <span class="token comment">// 每一批次训练的数据量</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token string">"model"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token string">"loss"</span><span class="token operator">:</span> <span class="token string">"mse"</span><span class="token punctuation">,</span>        <span class="token string">"optimizer"</span><span class="token operator">:</span> <span class="token string">"adam"</span><span class="token punctuation">,</span>        <span class="token string">"layers"</span><span class="token operator">:</span>            <span class="token punctuation">{</span>                <span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"lstm"</span><span class="token punctuation">,</span>                <span class="token string">"layers"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>        <span class="token comment">// 表示所搭建的模型具有2个LSTM层</span>                <span class="token string">"neurons"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>     <span class="token comment">// 表示所搭建的每个LSTM层都有100个神经元</span>                <span class="token string">"input_dim"</span><span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">,</span>     <span class="token comment">// 这里将0,1,2,5,6,11作为输入，是6维的</span>                <span class="token string">"output_dim"</span><span class="token operator">:</span> <span class="token number">1</span>     <span class="token comment">// 我们想要的预测结果是一维的风速，所以是1</span>            <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token string">"save_model"</span><span class="token operator">:</span> <span class="token number">1</span>             <span class="token comment">// 是否保存训练模型，是为1，反之为0</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>设置好了各项参数后，就该着手LSTM的模型搭建了，这里使用PyTorch框架完成LSTM的搭建。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">## file name: LSTM.pyimport torch.nn as nnimport torchdevice = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")class LSTM(nn.Module):    def __init__(self, input_dim, hidden_dim, num_layers, out_dim):        super(LSTM, self).__init__()        self.hidden_dim = hidden_dim        self.num_layers = num_layers        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)        self.fc = nn.Linear(hidden_dim, out_dim)    def forward(self, x):        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))        out = self.fc(out)        return out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-数据集划分"><a href="#3-数据集划分" class="headerlink" title="3.数据集划分"></a>3.数据集划分</h1><p>接下来需要将我们的数据集处理成模型可以读入的格式，在此之前我们需要定义一个<code>DataSet</code>类，方便我们完成对数据集的构建。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">## file name: dataloader.pyfrom torch.utils.data import Datasetclass DataSet(Dataset):    def __init__(self, x, y):        self.x = x        self.y = y    def __len__(self):        return len(self.x)    def __getitem__(self, index):        X = self.x[index]        Y = self.y[index]        return X, Y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于在处理数据时我们需要用到<code>config.json</code>文件中的参数，所以需要读取的参数，而Python提供了读取<code>.json</code>格式的模块，我们只需要输入<code>import json</code>调用即可。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">import jsonconfigs = json.load(open('config.json', 'r'))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>接下来就可以放心处理数据了，在处理数据的过程中，我们需要将数据划分为<em>训练集</em>和<em>测试集</em>两个部分，然后分别找出其中的<code>labels</code>以及<code>target</code>分别作为<code>x</code>和<code>y</code>即可。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">## file name: data_processer.pyimport jsonimport torchimport pandas as pdimport numpy as npfrom sklearn.preprocessing import MinMaxScalerfrom torch.utils.data import DataLoaderfrom dataloader import DataSetclass DataProcesser():    def data_processer(self):        configs = json.load(open('config.json', 'r'))        ## 载入数据        data = pd.read_excel('features.xlsx')        all_data = data.head(500)       # 为了方便计算选取了前500行作为原始数据        ## 数据预处理        scaler = MinMaxScaler(feature_range=(0, 1))     # 将数据压缩至0-1之间        sel_col = configs['data']['columns']        all_data = all_data[sel_col]        # 将数据集每个特征都压缩到0-1之间        for col in sel_col[1:]:            all_data[col] = scaler.fit_transform(all_data[col].values.reshape(-1, 1))        all_data = torch.tensor(np.array(all_data))        length = len(all_data)        tr_val_slip = int(configs['data']['train_test_split'] * length)              x = torch.zeros(length - configs['data']['sequence_length'], configs['data']['sequence_length'], configs['model']['layers']['input_dim'])        y = torch.zeros(length - configs['data']['sequence_length'], configs['data']['sequence_length'], configs['model']['layers']['output_dim'])        for i in range(0, length - configs['data']['sequence_length'] - 1):            x[i] = all_data[i: i + configs['data']['sequence_length']]            y[i] = all_data[i + 1: i + configs['data']['sequence_length'] + 1][:, 0].reshape(-1, 1)        train_x = x[0: tr_val_slip]        train_y = y[0: tr_val_slip]        valid_x = x[tr_val_slip:]        valid_y = y[tr_val_slip:]        train_set = DataSet(train_x, train_y)        valid_set = DataSet(valid_x, valid_y)        train_loader = DataLoader(train_set, batch_size=configs['training']['batch_size'], shuffle=False)        valid_loader = DataLoader(valid_set, batch_size=configs['training']['batch_size'], shuffle=False)        return train_loader, valid_loader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-模型训练"><a href="#4-模型训练" class="headerlink" title="4. 模型训练"></a>4. 模型训练</h1><p>接下来就是进行时间预测最耗时的部分了，此时我们需要对模型训练，与绝大部分深度学习框架相同，PyTorch同样支持cuda计算，但是为了避免有时GPU出现故障而无法使用时无法运行模型，这里对CPU与GPU进行选择：当GPU可以正常使用时使用GPU计算，反之使用CPU计算。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在进行模型训练时可以使用各种深度学习的可视化工具进行分析，例如PyTorch的<em>torchvision</em>，现在PyTorch也可以通过<em>tensorboardX</em>使用tensorflow的<em>tensorboard</em>。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">## file name: lstm_train.pyimport jsonimport torchimport timeimport matplotlibimport torch.nn as nnfrom LSTM import LSTMfrom data_processer import DataProcesserfrom matplotlib import pyplot as pltdevice = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")configs = json.load(open('config.json', 'r'))data_processer = DataProcesser()train_loader, valid_loader = data_processer.data_processer()lstm = LSTM(input_dim=configs['model']['layers']['input_dim'], hidden_dim=configs['model']['layers']['neurons'], out_dim=configs['model']['layers']['output_dim'],                                   num_layers=configs['model']['layers']['layers']).to(device)loss_function = nn.MSELoss()optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-4)tol_time = time.time()train_losses = []valid_losses = []for epoch in range(configs['training']['epochs']):    epoch_start_time = time.time()    train_loss = 0    train_acc = 0.    val_loss = 0    val_acc = 0.    lstm.train()    for i, data in enumerate(train_loader):        inputs, labels = data        y_pred = lstm(inputs)        loss = loss_function(y_pred, labels)        optimizer.zero_grad()        loss.backward()        optimizer.step()        train_loss += loss.item()    train_losses.append(train_loss)    lstm.eval()    with torch.no_grad():        for i, data in enumerate(valid_loader):            inputs, labels = data            val_pred = lstm(inputs)            loss = loss_function(val_pred, labels)            val_loss += loss.item()        valid_losses.append(val_loss)        if epoch % 100 == 0 and epoch != 0:            print('[%03d/%03d] Tra_Loss: %3.6f||val_Loss: %3.6f' % (epoch, configs['training']['epochs'], train_loss, val_loss))print("训练以及验证的总运行总时间：", time.time() - tol_time)if configs['model']['save_model']:    torch.save(lstm, 'lstm_model.pkl')figsize = 8,6fig = plt.figure(figsize=figsize)ax = fig.add_subplot(111)plt.subplots_adjust(left=0.08, right=0.94, bottom=0.06, top=0.94)plt.grid(True)plt.plot(train_losses, label='train_loss')plt.plot(valid_losses, label='valid_loss')plt.legend()plt.axis('tight')plt.setp(plt.gca().get_xticklabels(), rotation=50)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这里，我们选择手动收集训练过程中的<code>loss</code>，如图3所示。</p><img src="/2021/02/21/graduation-lstm/loss.png" width="400" height="300" alt="图3. 模型训练过程中的loss"><h1 id="5-模型预测"><a href="#5-模型预测" class="headerlink" title="5. 模型预测"></a>5. 模型预测</h1><p>在完成模型训练之后，就可以使用训练好的模型来进行预测了，这里进行预测的数据源自模型训练时的验证集，所以预测精度会很高，如图4所示。<br><img src="/2021/02/21/graduation-lstm/result.png" width="400" height="300" alt="图4. 模型预测结果"></p><pre class="line-numbers language-py" data-language="py"><code class="language-py">## file name: lstm.valid.pyimport jsonimport torchimport numpy as npfrom matplotlib import pyplot as pltfrom data_processer import DataProcesserdevice = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")configs = json.load(open('config.json', 'r'))lstm = torch.load('lstm_model.pkl')data_processer = DataProcesser()train_loader, valid_loader = data_processer.data_processer()y_valid_pred = lstm(valid_loader.dataset.x.to(device)).cpu()y_valid_pred = torch.squeeze(y_valid_pred, dim=2)y_valid_pred = y_valid_pred[:, configs['model']['layers']['input_dim']-1].detach().numpy()y_train = torch.squeeze(train_loader.dataset.y, dim=2)y_train = y_train[:, configs['model']['layers']['input_dim']-1 ].detach().numpy()y_valid = torch.squeeze(valid_loader.dataset.y, dim=2)y_valid = y_valid[:, configs['model']['layers']['input_dim']-1 ].detach().numpy()y = np.append(y_train, y_valid)figsize = 8,6fig = plt.figure(figsize=figsize)ax = fig.add_subplot(111)plt.subplots_adjust(left=0.08, right=0.94, bottom=0.06, top=0.94)plt.plot(y, label='observation')plt.plot(np.arange(len(y)-len(y_valid_pred), len(y)), y_valid_pred, label='prediction')plt.legend()plt.grid(True)plt.axis('tight')plt.setp(plt.gca().get_xticklabels(), rotation=50)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>本文源代码以上传github: <a href="https://github.com/Xiongzd/Xiongzd/tree/main/graduation-lstm">https://github.com/Xiongzd/Xiongzd/tree/main/graduation-lstm</a></p>]]></content>
      
      
      <categories>
          
          <category> 毕业设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> LSTM </tag>
            
            <tag> 时间序列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pretrained networks</title>
      <link href="2021/02/18/pytorch-2/"/>
      <url>2021/02/18/pytorch-2/</url>
      
        <content type="html"><![CDATA[<h1 id="2-预训练网络"><a href="#2-预训练网络" class="headerlink" title="2 预训练网络"></a>2 预训练网络</h1><p>本章将介绍</p><ul><li>运行预先训练好的图像识别模型</li><li>GANs 和 CycleGAN 的模型介绍</li><li>可生成图像文字描述的字幕模型</li><li>通过 Torch Hub 共享模型</li></ul><hr><h2 id="2-1-一种用来识别图像主体的预训练网络"><a href="#2-1-一种用来识别图像主体的预训练网络" class="headerlink" title="2.1 一种用来识别图像主体的预训练网络"></a>2.1 一种用来识别图像主体的预训练网络</h2><p>我们将在这里讨论的预训练网络是在ImageNet数据集的一个子集上训练的(<a href="http://imagenet.stanford.edu/">http://imagenet.stanford.edu</a>)<br>。ImageNet是一个非常大的数据集，由斯坦福大学维护超过1400万张图像。所有图像都使用来自WordNet数据集(<a href="http://wordnet.princeton.edu/">http://wordnet.princeton.edu</a>)<br>的名词层次结构进行标记，WordNet数据集又是英语语言的一个大型词汇数据库。</p><h3 id="2-1-1-获取用于图像识别的预训练网络"><a href="#2-1-1-获取用于图像识别的预训练网络" class="headerlink" title="2.1.1 获取用于图像识别的预训练网络"></a>2.1.1 获取用于图像识别的预训练网络</h3><p>现在，让我们加载并运行两个网络:第一个是AlexNet，早期的图像识别突破性网络之一;然后利用残差网络(简称ResNet)对ImageNet进行分类、检测和定位等。<br>预定义的模型可以在<code>torchvision.models</code>中找到</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">from torchvision import models<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们可以看看实际的模型：</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">dir(models)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-py" data-language="py"><code class="language-py">['AlexNet', 'DenseNet', 'GoogLeNet', 'Inception3', 'MNASNet', 'MobileNetV2', 'ResNet', 'ShuffleNetV2', 'SqueezeNet', 'VGG', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_utils', 'alexnet', 'densenet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'detection', 'googlenet', 'inception', 'inception_v3', 'mnasnet', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet', 'mobilenet_v2', 'resnet', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'segmentation', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'shufflenetv2', 'squeezenet', 'squeezenet1_0', 'squeezenet1_1', 'utils', 'vgg', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'video', 'wide_resnet101_2', 'wide_resnet50_2']<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>大写的名称指的是实现的许多六星模型的Python类，他们的结构体系不同——也就是说，在输入和输出之间发生的操作的安排不同。小写的名称是函数，他返回从这类实例化的模型，有时带有不同的参数集，例如resnet101返回一个有101层的ResNet实例，resnet18有18层，以此类推。现在让我们来看看AlexNet</p><h3 id="2-1-2-AlexNet"><a href="#2-1-2-AlexNet" class="headerlink" title="2.1.2 AlexNet"></a>2.1.2 AlexNet</h3><p>为了在输入映像上运行AlexNet结构，我们可以创建AlexNet类的一个实例：</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">alexnet = models.AlexNet()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时，<code>alexnet</code>是一个可以运行<code>AlexNet</code>体系结构的对象。</p><h3 id="2-1-3-ResNet"><a href="#2-1-3-ResNet" class="headerlink" title="2.1.3 ResNet"></a>2.1.3 ResNet</h3><p>现在使用<code>resnet101</code>函数来实例化一个101层的卷积神经网络。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">resnet = models.resnet101(pretrained=True)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当我们盯着下载进度时，我们可以花一分钟时间来欣赏<code>resnet101</code>的4450万个参数——这是大量需要自动优化的参数!</p><h3 id="2-1-4-准备工作及运行"><a href="#2-1-4-准备工作及运行" class="headerlink" title="2.1.4 准备工作及运行"></a>2.1.4 准备工作及运行</h3><pre class="line-numbers language-py" data-language="py"><code class="language-py">ResNet(  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  (relu): ReLU(inplace=True)  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)  (layer1): Sequential(    (0): Bottleneck(...    )  )  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))  (fc): Linear(in_features=2048, out_features=1000, bias=True))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以像函数一样调用<code>resnet</code>变量，将一个或多个图像作为输入，并为1000个ImageNet类中的每个类生成相同数量的分数。然而，在这样做之前，必须对输入图像进行预处理，使他们具有正确的大小，并为他们的值（颜色）位于大致相同的数值范围内。为了做到这一点，<code>torchvision</code>模块中提供了<code>transforms</code>，他允许我们快速定义基本预处理函数的流程：</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">from torchvision import transformspreprocess = transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在本例中，我们定义了一个预处理函数，他将输入图像缩放到256x256，围绕中心剪裁224x224， 并将其转换为一个张量，并进行标准化，使其具有定义的均值和标准差。</p><p>现在，我们可以抓拍一张我们最喜欢的狗的照片(比如，来自GitHub repo的bobby.jpg)，对它进行预处理，然后看看ResNet对它有什么看法。我们可以从使用Pillow从本地文件系统加载一个图像开始，Pillow是Python的一个图像处理模块:</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">from PIL improt Imageimg = Image.open("data/bobby.jpg")img.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>使用<code>show</code>方法，可以查看图像，如图1所示。<br><img src="/2021/02/18/pytorch-2/bobby.jpg" width="400" height="300" alt="图1. 输入图片, Bobby"></p><p>接下来可以使用预处理管道传递函数：</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">img_t = preprocess(img)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后可以按照network期望的方式对张量进行reshape，crop以及normalize等操作。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">import torchbatch_t = torch.unsqueeze(img_t, 0)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>现在我们就可以运行我们的模型了</p><h3 id="2-1-5-运行"><a href="#2-1-5-运行" class="headerlink" title="2.1.5 运行"></a>2.1.5 运行</h3><p>在深度学习领域，在新数据上运行一个训练过的模型被称为<em>inference</em>。为了执行该操作，需要将网络置于<code>eval</code>模式。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">resnet.eval()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果忘记真么做，一些预训练好的模型，例如<em>bathch normalization</em>和<em>dropout</em>，将会产生无意义的结果。既然现在<code>eval</code>模式已经设置好了，我们可以进行<em>inference</em>了。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">out = resnet(batch_t)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>经过一组涉及4450万个参数的令人震惊的操作刚刚发生，生成了一个包含1000个分数的向量，每个ImageNet类一个分数，并且并没有花费多长时间。</p><p>我们现在需要找到获得最高分数的类的标签，这会告诉我们模型在图像中看到了什么，如果标签符合人类对图像的描述，那就意味着我们的模型运行的很好。如果不是，那么要么是训练过程中出现了问题，要么是图像与模型预期的差异太大，以至于模型不能正确地处理他，又或者是其他类似的问题。</p><p>为了查看预测标签的列表，我们需要加载一个文本文件，该文本文件列出了在训练过程中呈现给网络的标签的相同顺序，然后我们将从网络中挑选出得分最高的所引出的标签。几乎所有用于图像识别的模型都以类似于此的形式输出的。</p><p>让我们加载包含ImageNet数据集类的1000个标签。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">with open("data/imagenet_classes.txt") as f:    labels = [line.strip() for line in f.readlines()]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>此时，我们需要确定我们之前获得的<code>out</code>张量中获得最大分数的的索引。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">_, index = torch.max(out, 1)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在需要通过使用索引来访问标签。在这里，<code>index</code>不是一个一般的普通的Python数字，而是一个一维的张量(例如<code>tensor([207])</code>)，所以需要使用<code>index[0]</code>来获取实际的值作为<code>labels</code>列表的索引。同时，使用<code>torch.nn.functional.softmax</code>将输出归一化，然后除以总和。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">percentage = torch.nn.functional.softmax(out, dim=1)[0] *100print(labels[index[0]], percentage[index[0]].item())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>将预测结果及分数打印出来</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">golden retriever 96.57185363769531<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时，我们也可以基于该模型找到分数第二、第三的类，为此可以使用<code>sort</code>函数，进行排序。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">percentage = torch.nn.functional.softmax(out, dim=1)[0] *100print(labels[index[0]], percentage[index[0]].item())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>将结果打印</p><pre class="line-numbers language-none"><code class="language-none">golden retriever 96.57185363769531golden retriever 96.57185363769531Labrador retriever 2.6082682609558105cocker spaniel, English cocker spaniel, cocker 0.26996296644210815redbone 0.17959004640579224tennis ball 0.10991978645324707<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们看到前四种是狗，然而第五个答案却是“网球”，可能是因为在训练时有足够多的网球和狗在一起的图片，所以模型是在说“有0.1%的可能性我完全误解了网球是什么。”这是一个很好的例子，说明了人类和神经网络在看待世界的方式上存在根本差异，以及奇怪、微妙的偏见很容易潜入我们的数据。</p><p>接下来，是时候看看其他不同的架构来实现其他类型的任务了，首先从图像生成开始。</p><h2 id="2-2-冒充他！代替他！"><a href="#2-2-冒充他！代替他！" class="headerlink" title="2.2 冒充他！代替他！"></a>2.2 冒充他！代替他！</h2><p>让我们暂时假设，我们是职业罪犯，想要出售著名艺术家“遗失”画作的赝品。我们是罪犯，不是画家，所以当我们画出伦勃朗和毕加索的赝品时，很快就会发现它们都是业余仿制品，而不是真品。即使我们花了很多时间练习直到找到一幅我们认不出是赝品的油画，想把它卖给当地的艺术品拍卖行也会让我们马上被踢出去。更糟糕的是，被告知“这明显是假的;“滚出去”并不能帮助我们提高!我们必须随机尝试许多东西，判断哪些需要更长的时间才能识别为赝品，并在未来的尝试中强调这些特征，而这需要的时间太长了。</p><p>相反，我们需要找一个道德地位有问题的艺术史学家来检查我们的作品，并确切地告诉我们是什么原因让他们认为这幅画不合法。有了这些反馈，我们可以以清晰、直接的方式提高我们的输出，直到我们的粗略学者再也无法分辨我们的画和真实的东西。</p><p>很快，我们的《波提切利》就会在卢浮宫展出，他们的钞票也会在我们口袋里。我们会发财!</p><p>虽然听起来有些荒唐，但是其技术基础是可靠的，并可能会在未来几年后对数字数据的感知准确性产生深远的影响。“photographic evidence”的整个概念可能会变得令人怀疑，因为自动化生产令人信服但虚假的图像和视频是多么容易，唯一的关键因素就是数据，让我们看看这个过程是如何运作的。</p><h3 id="2-2-1-The-GAN-game"><a href="#2-2-1-The-GAN-game" class="headerlink" title="2.2.1 The GAN game"></a>2.2.1 The GAN game</h3><p>在深度学习的背景下，我们刚刚描述的被称为 <em>GAN game</em>，其中两个网络，一个作为画家，另一个作为艺术历史学家，在创造和发现赝品方面比对方更聪明。GAN代表生成对抗网络<em>generative adversarial network</em>，在这里<em>generative</em>意味着某些东西正在被创造(在这种情况下，是伪造的杰作)，而<em>adversarial</em>则意味着这两个网络正在竞争以战胜对方，这些网络是最近深度学习研究的最原始成果之一。</p><h3 id="2-2-2-CycleGAN"><a href="#2-2-2-CycleGAN" class="headerlink" title="2.2.2 CycleGAN"></a>2.2.2 CycleGAN</h3><p>这一概念的一个有趣的演变是 CycleGAN。一个 CycleGAN 可以讲一个域的图像转换为另一个域的图像(反之亦然)，而不需要我们在训练集中明确地提供匹配对。</p><h3 id="2-2-3-将马变为斑马的网络"><a href="#2-2-3-将马变为斑马的网络" class="headerlink" title="2.2.3 将马变为斑马的网络"></a>2.2.3 将马变为斑马的网络</h3><p>我们将使用 CycleGAN 网络将马变成斑马。CycleGAN 网络已经从ImageNet数据集中提取的马和斑马的图像数据集上进行了训练。</p><p>我们需要定义一个<code>ResNetGenerator</code>类，其实现较为复杂，先不做解释。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">netG = ResNetGenerator()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时<code>netG</code>模型已经创建，但它包含随机权重。我们前面提到过，我们将运行一个在horse2zebra数据集上预先训练过的生成器模型，它的训练集包含两组马和斑马的图像，分别是1068和1335张。数据集可以在 (<a href="http://mng.bz/8pKP">http://mng.bz/8pKP</a>) 找到。</p><p>模型的权重保存在一个.pth文件中。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">model_path = 'data/horse2zebra_0.4.0.pth'model_data = torch.load(model_path)netG.load_state_dict(model_data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>至此，<code>netG</code>已经获得了他在培训中获得的所有知识。接下来将network置于<code>eval</code>模式。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">netG.eval()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>就像之前所做的，这里模仿2.1的流程。</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">from PIL import Imagefrom torchvision import transforms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>同样的，将图像转换成network需要的shape和size：</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">preprocess = transforms.Compose([transforms.Resize(256),                                 transforms.ToTensor()])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>接下来选择一张马的图片，并将其中的马变成斑马<br><img src="/2021/02/18/pytorch-2/horse.jpg" width="400" height="300" alt="图2.马"></p><pre class="line-numbers language-py" data-language="py"><code class="language-py">img = Image.open("../data/p1ch2/horse.jpg")img_t = preprocess(img)batch_t = torch.unsqueeze(img_t, 0)batch_out = netG(batch_t)out_t = (batch_out.data.squeeze() + 1.0) / 2.0out_img = transforms.ToPILImage()(out_t)out_img.save('data/zebra.jpg')out_img.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2021/02/18/pytorch-2/zebra.jpg" width="400" height="300" alt="图3. 将马变成斑马"><p>源代码</p><pre class="line-numbers language-py" data-language="py"><code class="language-py">## 2.1 A pretrained network that recognizes the subject of an imagefrom torchvision import modelsfrom torchvision import transformsfrom PIL import Imageimport torchimport torch.nn as nnresnet = models.resnet101(pretrained=True)preprocess = transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])img = Image.open("data/bobby.jpg")# img.show()img_t = preprocess(img)batch_t = torch.unsqueeze(img_t, 0)resnet.eval()out = resnet(batch_t)# print(out)with open("data/imagenet_classes.txt") as f:    labels = [line.strip() for line in f.readlines()]_, index = torch.max(out, 1)# print(out.size())percentage = torch.nn.functional.softmax(out, dim=1)[0] *100print(labels[index[0]], percentage[index[0]].item())_, indices = torch.sort(out, descending=True)[print(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-py" data-language="py"><code class="language-py">## 2.2 A pretrained model that fakes it until it makes itfrom torchvision import modelsfrom torchvision import transformsfrom PIL import Imageimport torchimport torch.nn as nnclass ResNetBlock(nn.Module): # &lt;1&gt;    def __init__(self, dim):        super(ResNetBlock, self).__init__()        self.conv_block = self.build_conv_block(dim)    def build_conv_block(self, dim):        conv_block = []        conv_block += [nn.ReflectionPad2d(1)]        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),                       nn.InstanceNorm2d(dim),                       nn.ReLU(True)]        conv_block += [nn.ReflectionPad2d(1)]        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),                       nn.InstanceNorm2d(dim)]        return nn.Sequential(*conv_block)    def forward(self, x):        out = x + self.conv_block(x) # &lt;2&gt;        return outclass ResNetGenerator(nn.Module):    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9): # &lt;3&gt;         assert(n_blocks &gt;= 0)        super(ResNetGenerator, self).__init__()        self.input_nc = input_nc        self.output_nc = output_nc        self.ngf = ngf        model = [nn.ReflectionPad2d(3),                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=True),                 nn.InstanceNorm2d(ngf),                 nn.ReLU(True)]        n_downsampling = 2        for i in range(n_downsampling):            mult = 2**i            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,                                stride=2, padding=1, bias=True),                      nn.InstanceNorm2d(ngf * mult * 2),                      nn.ReLU(True)]        mult = 2**n_downsampling        for i in range(n_blocks):            model += [ResNetBlock(ngf * mult)]        for i in range(n_downsampling):            mult = 2**(n_downsampling - i)            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),                                         kernel_size=3, stride=2,                                         padding=1, output_padding=1,                                         bias=True),                      nn.InstanceNorm2d(int(ngf * mult / 2)),                      nn.ReLU(True)]        model += [nn.ReflectionPad2d(3)]        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]        model += [nn.Tanh()]        self.model = nn.Sequential(*model)    def forward(self, input): # &lt;3&gt;        return self.model(input)netG = ResNetGenerator()# model_path = '../data/p1ch2/horse2zebra_0.4.0.pth'model_path = 'data\horse2zebra_0.4.0.pth'model_data = torch.load(model_path)netG.load_state_dict(model_data)netG.eval()preprocess = transforms.Compose([transforms.Resize(256),                                 transforms.ToTensor()])# img = Image.open("../data/p1ch2/horse.jpg")img = Image.open("data/horse.jpg")img_t = preprocess(img)batch_t = torch.unsqueeze(img_t, 0)batch_out = netG(batch_t)out_t = (batch_out.data.squeeze() + 1.0) / 2.0out_img = transforms.ToPILImage()(out_t)out_img.save('data/zebra.jpg')out_img.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DeepLearning </tag>
            
            <tag> PyTorch </tag>
            
            <tag> Tutorial </tag>
            
            <tag> DeepLearning with Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>雾环状流动的参数计算</title>
      <link href="2021/01/31/fog-circulation/"/>
      <url>2021/01/31/fog-circulation/</url>
      
        <content type="html"><![CDATA[<h2 id="雾环状流动的参数计算"><a href="#雾环状流动的参数计算" class="headerlink" title="雾环状流动的参数计算"></a>雾环状流动的参数计算</h2><h4 id="1-使用分相流模型估算摩阻梯度"><a href="#1-使用分相流模型估算摩阻梯度" class="headerlink" title="1.使用分相流模型估算摩阻梯度"></a>1.使用分相流模型估算摩阻梯度</h4><p>$先计算气相和液相的折算流速W’’和W’，并根据此求出雷诺数$<br>$$<br>    j_ { g } =\frac { M’’ }  { A\rho’’ }  = \frac { 0.1 }  { 1.64\times\pi\times0.03^ { 2 } /4 }  = 86.31 m/s<br>$$</p><p>$$<br>j_ { f }  = \frac { M’ }  { A\rho’ }  = \frac { 0.2 }  { 1000\times\pi\times 0.03^ { 2 } /4  }  = 0.1415 m/s<br>$$ </p><p>$$<br>Re_ { f } =\frac { j_ { f } \rho’ D }  { \mu’ } =\frac { 0.1415\times1000\times0.03 }  { 1\times10^ { -3 }  }  = 422449<br>$$</p><p>$$<br>Re_ { g }  = \frac { j_ { g } \rho’’D }  { \mu’’ } =\frac { 86.31\times1.64\times0.03 }  { 1.8\times10^ { -5 }  } =235914<br>$$</p><p>$可以看出两相均为湍流。再按布拉修斯公式计算出摩阻系数\lambda_ { l } 和\lambda_ { g } 。$</p><p>$$<br>\lambda_ { f } =0.3164Re_ { f } ^ { -0.25 }  = 0.3164\times42449^ { -0.25 } =0.022<br>$$</p><p>$$<br>\lambda_ { g }  = 0.3164Re_ { g } ^ { -0.25 }  = 0.3164\times235914=0.0109<br>$$</p><p>$再计算出分液相及分气相的摩阻梯度(\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { l } 和(\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { g } $</p><p>$$<br>(\frac { \mathrm { d } p_ { g }  }  { \mathrm { d } z } )_ { g } =\frac { \lambda_ { g }  }  { D } \frac { G^ { 2 } x^ { 2 }  }  { 2\rho’’ } =2175 Pa/m<br>$$</p><p>$由此计算出马蒂内利参数$<br>$$    X^ { 2 } =\frac { (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { l }  }  { (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { g }  } =0.137<br>$$</p><p>$再由奇斯霍姆式求出气相折算系数$<br>$$    \Phi_ { g } ^ { 2 } =1+20X+X^ { 2 }  = 8.573<br>$$</p><p>$同样的计算出液相折算系数$<br>$$    \Phi_ { l } ^ { 2 }  = 1 + \frac { 20 }  { X }  + \frac { 1 }  { X^ { 2 }  }  =62.35<br>$$</p><p>$最后估算出两相压降梯度$<br>$$    \frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z }  = \Phi_ { g } ^ { 2 } (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { g } =18646Pa/m<br>$$</p><p>$$    \frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z }  = \Phi_ { g } ^ { 2 } (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { g } =18456Pa/m<br>$$  </p><h4 id="2-计算窜流比"><a href="#2-计算窜流比" class="headerlink" title="2. 计算窜流比"></a>2. 计算窜流比</h4><p>$首先计算出无因次量  \bar { Y } $</p><p>$$     \bar { Y } =\frac { j_ { g } \mu’’ }  { \sigma } \cdot(\frac { \rho’’ }  { \rho’ } )\times10^ { 4 } =8.74<br>$$ $再计算出窜流比值  E $ </p><p>$$    E=0.400038\times(8.7404)^ { 0.2875 } =0.6257<br>$$</p><h4 id="3-计算气流夹带水滴工况下的分液相折算系数-Phi-lE-2"><a href="#3-计算气流夹带水滴工况下的分液相折算系数-Phi-lE-2" class="headerlink" title="3. 计算气流夹带水滴工况下的分液相折算系数$\Phi_ { lE } ^ { 2 } $"></a>3. 计算气流夹带水滴工况下的分液相折算系数$\Phi_ { lE } ^ { 2 } $</h4><p>$先计算出入窜流量的雷诺数$<br>$$    Re_ { lE } =Re_ { l } (1-E)=15887<br>$$</p><p>$据此算出摩阻系数$<br>$$<br>    \lambda_ { lE } =0.3164Re_ { lE } ^ { -0.25 } =0.02818<br>$$</p><p>$计算出扣除被气流带走的水滴后的液相折算速度$<br>$$<br>    j_ { E } =\frac { M’(1-E) }  { \rho’A } =0.106m/s<br>$$ </p><p>$算出气流夹带水滴时的分液相摩阻梯度$<br>$$<br>    (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { lE } =\frac { \lambda_ { lE }  }  { D } \frac { \rho’j_ { E } ‘^ { 2 }  }  { 2 } =5.277<br>$$</p><p>$然后计算出计入窜流量的分液相折算系数$<br>$$<br>    \Phi_ { lE } ^ { 2 } =\frac { \frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z }  }  { (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { lE }  } =3517<br>$$</p><h4 id="4-计算雾环状流的截面含气率"><a href="#4-计算雾环状流的截面含气率" class="headerlink" title="4.计算雾环状流的截面含气率"></a>4.计算雾环状流的截面含气率</h4><p>$由下式计算出雾环状流的截面含气率$<br>$$<br>    (1-\alpha)^ { 2 }  =\frac { 1 }  { \Phi_ { l } ^ { 2 }  }<br>$$</p><p>$可以计算得到$<br>$$<br>    \alpha = 1-\frac { 1 }  { \Phi_ { l }  }  = 0.872<br>$$</p><h4 id="5-计算两相摩阻梯度"><a href="#5-计算两相摩阻梯度" class="headerlink" title="5. 计算两相摩阻梯度"></a>5. 计算两相摩阻梯度</h4><p>$先按照下式子求出  \Phi_ { g } ^ { 2 } $</p>$$\Phi_{g}^{2}=\left[\frac{1+75\left(1-\alpha\right)}{{{\alpha}^{{}^{5}/{}_{2}}}}\right]\left(\frac{{M}''+E{M}''}{{{M}''}}\right){{\left\{1-2\left(\frac{\alpha}{1-\alpha}\right)\left(\frac{{{\rho}''}}{{{\rho}'}}\right)\left[\frac{{M}'\left(1-E\right)}{{{M}''}}\right]\right\}}^{2}}=32.495$$<p>$再求得两相摩阻梯度$<br>$$<br>    \frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } =\Phi_ { g } ^ { 2 } (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { g } =70676 Pa/m<br>$$</p><p>$对\Phi_ { g } ^ { 2 } 进行迭代计算，如图1所示，\Phi_ { g } ^ { 2 } 的值已经收敛，最终可以得到 \alpha = 0.9779,\Phi_ { g } ^ { 2 } =5.0079,\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } =10892。$</p><p>$带入公式计算$<br><img src="/2021/01/31/fog-circulation/Figure_1.svg" width="400" height="300" alt="图1.不同迭代次数下$\Phi_ { g } ^ { 2 } $的值"></p><p>$$<br>    (\frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z } )_ { g } =\frac { \frac { \mathrm { d } p_ { f }  }  { \mathrm { d } z }  }  { \Phi_ { g } ^ { 2 }  }  = 2175 Pa/m<br>$$</p><p>$通过下式计算液膜厚度\delta$<br>$$<br>    \alpha = 1 - 4\frac { \delta }  { D }<br>$$</p><p>$最终得到液膜厚度\delta$<br>$$<br>    \delta = \frac { (1-\alpha)D }  { 4 }  = 0.1658 mm<br>$$ </p><h4 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h4><pre class="line-numbers language-py" data-language="py"><code class="language-py">import numpy as npimport matplotlib.pyplot as pltfrom math import *# 常量M_g = 0.1M_f = 0.2E = 0.6257rho_g = 1.64rho_f = 1000mu_g = 1.8e-5mu_f = 1e-3grad_Pg = 2175grad_PlE = 5.277# 初始值alpha = 0.872Phi_g_2 = 8.573Phi_lE_2 = 3517grad_P = 18646def Phig2(alpha , M_f, M_g, rho_f, rho_g, E):    a = ((1+75*(1-alpha))/(alpha ** (5/2)))    b = ((M_g + E * M_f)/M_g)    c = (1-2*(alpha/(1-alpha))*(rho_g/rho_f)*(M_f*(1-E)/M_g))**2    return a * b * cdef gradPf(Phi_g_2, grad_Pg):    return Phi_g_2 * grad_Pgif __name__ == '__main__':    ans = []    for k in range(1000):        Phi_g_2 = Phig2(alpha, M_f, M_g, rho_f, rho_g, E)        grad_P_new =  gradPf(Phi_g_2, grad_Pg)        if (fabs(grad_P_new - grad_P)&lt; 1e-8):            break        grad_P = grad_P_new        Phi_lE_2 = grad_P_new / grad_PlE        alpha = 1 - 1 / sqrt(Phi_lE_2)        ans.append(Phi_g_2)plt.plot(np.linspace(0,len(ans),len(ans)),ans)plt.scatter(np.linspace(0,len(ans),len(ans)),ans)plt.show()print(Phi_g_2)print(alpha)print(grad_P_new)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 两相流与传热 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 两相流与传热 </tag>
            
            <tag> 大学课程 </tag>
            
            <tag> 雾环状流动 </tag>
            
            <tag> 摩阻分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2021/01/30/hello-world/"/>
      <url>2021/01/30/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>公告</title>
      <link href="2021/01/30/gong-gao/"/>
      <url>2021/01/30/gong-gao/</url>
      
        <content type="html"><![CDATA[<h4 id="请美丽可爱又善良的单身小姐姐务必加我好友，谢谢合作"><a href="#请美丽可爱又善良的单身小姐姐务必加我好友，谢谢合作" class="headerlink" title="请美丽可爱又善良的单身小姐姐务必加我好友，谢谢合作"></a><span style="color:#FF00FF;background:背景颜色;font-size:文字大小;font-family:;">请美丽可爱又善良的单身小姐姐务必加我好友，谢谢合作</span></h4><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2021.1.30 使用cdn加速首页图片加载</p><p>2021.1.31 增加公告栏</p><p><span style="color:#FF3030;background:背景颜色;font-size:文字大小;font-family:;">2021.1.31 开放评论系统，请大家多多留言</span></p>]]></content>
      
      
      <categories>
          
          <category> 公告 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 公告 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
